{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fichero «titanic.csv» contiene información sobre los pasajeros del Titanic. Escribir un programa\n",
    "con los siguientes requisitos:\n",
    "1. Generar un DataFrame con los datos del fichero.\n",
    "2. Mostrar por pantalla las dimensiones del DataFrame, el número de datos que contiene, los\n",
    "nombres de sus columnas, los tipos de datos de las columnas, las 10 primeras filas y las 10\n",
    "últimas filas\n",
    "3. Mostrar por pantalla los datos del pasajero con identificador 148.\n",
    "4. Mostrar por pantalla las filas pares del DataFrame.\n",
    "5. Mostrar por pantalla los nombres de las personas que iban en primera clase ordenadas\n",
    "alfabéticamente.\n",
    "6. Mostrar por pantalla el porcentaje de personas que sobrevivieron y murieron.\n",
    "7. Mostrar por pantalla el porcentaje de personas que sobrevivieron en cada clase.\n",
    "8. Eliminar del DataFrame los pasajeros con edad desconocida.\n",
    "9. Mostrar por pantalla la edad media de las mujeres que viajaban en cada clase.\n",
    "10. Añadir una nueva columna booleana para ver si el pasajero era menor de edad o no.\n",
    "11. Mostrar por pantalla el porcentaje de menores y mayores de edad que sobrevivieron en cada\n",
    "clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#1\n",
    "titanic_df = pd.read_csv('titanic.csv')\n",
    "#2\n",
    "titanic_df.info()\n",
    "titanic_df.head(10)\n",
    "titanic_df.tail(10)\n",
    "#3\n",
    "titanic_df.query('PassengerId == 148')\n",
    "#4\n",
    "titanic_df[::2]\n",
    "#5\n",
    "titanic_df.query('Pclass == 1').sort_values('Name')\n",
    "#6\n",
    "supervivientes = titanic_df.agg({'Survived':'mean'})\n",
    "datos = [supervivientes['Survived'], 1-supervivientes['Survived']]\n",
    "etiquetas = ['Supervivientes', 'Víctimas']\n",
    "plt.pie(datos, labels=etiquetas, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Porcentaje de supervivientes y víctimas')\n",
    "plt.show()\n",
    "#7\n",
    "supervivientes = titanic_df.groupby('Pclass').agg({'Survived':'mean'})\n",
    "supervivientes = supervivientes['Survived'].apply(lambda x: x*100)\n",
    "supervivientes.plot(kind='bar').set_ylim(0,100)\n",
    "plt.title('Porcentaje de supervivientes por clase')\n",
    "plt.show()\n",
    "#8\n",
    "titanic_df = titanic_df.dropna(subset=['Age'])\n",
    "titanic_df['Age'].unique()\n",
    "#9\n",
    "titanic_df.query(\"Sex == 'female'\").groupby(\"Pclass\").agg({'Age':'mean'})\n",
    "#10\n",
    "titanic_df.loc[titanic_df.query('Age < 18').index, 'menor'] = True\n",
    "titanic_df.loc[titanic_df.query('Age >= 18').index, 'menor'] = False\n",
    "#11\n",
    "menores = titanic_df.groupby(\"menor\").agg({'menor':'count'})\n",
    "menores.plot(kind='pie', labels=['Mayor', 'Menor'],subplots='True', autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Porcentaje de menores y mayores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ficheros emisiones-2016.csv, emisiones-2017.csv, emisiones-2018.csv y emisiones-2019.csv,\n",
    "contienen datos sobre las emisiones contaminates en la ciudad de Madrid en los años 2016, 2017,\n",
    "2018 y 2019 respectivamente. Escribir un programa con los siguientes requisitos:\n",
    "1. Generar un DataFrame con los datos de los cuatro ficheros.\n",
    "2. Filtrar las columnas del DataFrame para quedarse con las columnas ESTACION,\n",
    "MAGNITUD, AÑO, MES y las correspondientes a los días D01, D02, etc.\n",
    "3. Reestructurar el DataFrame para que los valores de los contaminantes de las columnas de los\n",
    "días aparezcan en una única columna.\n",
    "4. Añadir una columna con la fecha a partir de la concatenación del año, el mes y el día (usar el\n",
    "módulo datetime).\n",
    "5. Eliminar las filas con fechas no válidas (utilizar la función isnat del módulo numpy) y\n",
    "ordenar el DataFrame por estaciones contaminantes y fecha.\n",
    "6. Mostrar por pantalla las estaciones y los contaminantes disponibles en el DataFrame.\n",
    "7. Crear una función que reciba una estación, un contaminante y un rango de fechas y devuelva\n",
    "una serie con las emisiones del contaminante dado en la estación y rango de fechas dado.\n",
    "8. Mostrar un resumen descriptivo (mínimo, máximo, media, etc.) para cada contaminante.\n",
    "9. Mostrar un resumen descriptivo para cada contaminante por distritos.\n",
    "10. Crear una función que reciba una estación y un contaminante y devuelva un resumen\n",
    "descriptivo de las emisiones del contaminante indicado en la estación indicada.\n",
    "11. Crear una función que devuelva las emisiones medias mensuales de un contaminante y un\n",
    "año dados para todos las estaciones.\n",
    "12. Crear un función que reciba una estación de medición y devuelva un DataFrame con las\n",
    "medias mensuales de los distintos tipos de contaminantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "emisiones_2016 = pd.read_csv('emisiones-2016.csv', delimiter=';')\n",
    "emisiones_2017 = pd.read_csv('emisiones-2017.csv', delimiter=';')\n",
    "emisiones_2018 = pd.read_csv('emisiones-2018.csv', delimiter=';')\n",
    "emisiones_2019 = pd.read_csv('emisiones-2019.csv', delimiter=';')\n",
    "emisiones_df = pd.concat([emisiones_2016, emisiones_2017, emisiones_2018, emisiones_2019])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48ed48f5542fe07e8f725768fb6d295eb9c66c05001f1d4e389bf0879d8b38cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
